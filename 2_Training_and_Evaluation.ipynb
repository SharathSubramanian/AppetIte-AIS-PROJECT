{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93a2e90f-12d2-40c2-ac54-f25ea24eceb3",
   "metadata": {},
   "source": [
    "## 02 — Train Flan-T5-Base + LoRA for AppetIte\n",
    "\n",
    "This notebook fine-tunes **google/flan-t5-base** using **LoRA** on the AppetIte dataset.\n",
    "\n",
    "Goals:\n",
    "- Input: ingredients list\n",
    "- Output: recipe title + step-by-step instructions\n",
    "- Model: Flan-T5-Base (instruction-tuned)\n",
    "- Fine-tuning: LoRA (parameter-efficient, M2-friendly)\n",
    "\n",
    "Assumptions:\n",
    "- Preprocessed CSVs are available in `data/processed/`:\n",
    "  - `appetite_train.csv`\n",
    "  - `appetite_val.csv`\n",
    "  - `appetite_test.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f57ee426-a1b0-4cb5-9b75-efe3f307c546",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets peft evaluate sacrebleu sentencepiece accelerate --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5367500-aea2-45c9-9100-02cc44b47094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "import evaluate\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdbef9f5-418d-4415-b3fe-5525631fcc16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for obj_name in [\"model\", \"trainer\"]:\n",
    "    if obj_name in globals():\n",
    "        del globals()[obj_name]\n",
    "\n",
    "gc.collect()\n",
    "if torch.backends.mps.is_available():\n",
    "    torch.mps.empty_cache()\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4644922f-aed9-4b90-92c7-0da7387f1671",
   "metadata": {},
   "source": [
    "### Load Processed AppetIte Dataset\n",
    "\n",
    "We load the cleaned CSV files produced by the preprocessing notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84646d48-91b5-4787-aa86-a6e5a21fa913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>ingredients_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>Image_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3-Ingredient Sweet Potato Casserole with Maple...</td>\n",
       "      <td>Olive oil (for pan), 5 1/2 pounds sweet potato...</td>\n",
       "      <td>Title: 3-Ingredient Sweet Potato Casserole wit...</td>\n",
       "      <td>3-ingredient-sweet-potato-casserole-with-maple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sea Bass with Marinated Vegetables</td>\n",
       "      <td>1 ripe medium tomato, 1 garlic clove, smashed,...</td>\n",
       "      <td>Title: Sea Bass with Marinated Vegetables\\nIns...</td>\n",
       "      <td>sea-bass-with-marinated-vegetables-242301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spicy Pork Posole</td>\n",
       "      <td>1 tablespoon olive oil, 6 ounces pork tenderlo...</td>\n",
       "      <td>Title: Spicy Pork Posole\\nInstructions: Heat o...</td>\n",
       "      <td>spicy-pork-posole-357091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roast Pork Belly Toasts with Blood-Orange BBQ ...</td>\n",
       "      <td>One 2-pound piece of boneless, skinless pork b...</td>\n",
       "      <td>Title: Roast Pork Belly Toasts with Blood-Oran...</td>\n",
       "      <td>roast-pork-belly-toasts-with-blood-orange-bbq-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Farmers' Market Salad with Spiced Goat Cheese ...</td>\n",
       "      <td>2 tablespoons sesame seeds, 2 teaspoons ground...</td>\n",
       "      <td>Title: Farmers' Market Salad with Spiced Goat ...</td>\n",
       "      <td>farmers-market-salad-with-spiced-goat-cheese-r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  3-Ingredient Sweet Potato Casserole with Maple...   \n",
       "1                 Sea Bass with Marinated Vegetables   \n",
       "2                                  Spicy Pork Posole   \n",
       "3  Roast Pork Belly Toasts with Blood-Orange BBQ ...   \n",
       "4  Farmers' Market Salad with Spiced Goat Cheese ...   \n",
       "\n",
       "                                    ingredients_text  \\\n",
       "0  Olive oil (for pan), 5 1/2 pounds sweet potato...   \n",
       "1  1 ripe medium tomato, 1 garlic clove, smashed,...   \n",
       "2  1 tablespoon olive oil, 6 ounces pork tenderlo...   \n",
       "3  One 2-pound piece of boneless, skinless pork b...   \n",
       "4  2 tablespoons sesame seeds, 2 teaspoons ground...   \n",
       "\n",
       "                                         target_text  \\\n",
       "0  Title: 3-Ingredient Sweet Potato Casserole wit...   \n",
       "1  Title: Sea Bass with Marinated Vegetables\\nIns...   \n",
       "2  Title: Spicy Pork Posole\\nInstructions: Heat o...   \n",
       "3  Title: Roast Pork Belly Toasts with Blood-Oran...   \n",
       "4  Title: Farmers' Market Salad with Spiced Goat ...   \n",
       "\n",
       "                                          Image_Name  \n",
       "0  3-ingredient-sweet-potato-casserole-with-maple...  \n",
       "1          sea-bass-with-marinated-vegetables-242301  \n",
       "2                           spicy-pork-posole-357091  \n",
       "3  roast-pork-belly-toasts-with-blood-orange-bbq-...  \n",
       "4  farmers-market-salad-with-spiced-goat-cheese-r...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"data/processed/appetite_train.csv\")\n",
    "val_df   = pd.read_csv(\"data/processed/appetite_val.csv\")\n",
    "test_df  = pd.read_csv(\"data/processed/appetite_test.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa209dad-5891-4fc5-a9b3-81dd0fa834da",
   "metadata": {},
   "source": [
    "### Final Text Sanitization\n",
    "\n",
    "We ensure all text fields are proper strings, with no NaN, None, or list objects.\n",
    "This prevents tokenizer crashes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ff9bc20-25ec-4c65-89e3-dafddccc0e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_field(x):\n",
    "    if x is None:\n",
    "        return \"\"\n",
    "    if isinstance(x, float):  # catches NaN\n",
    "        return \"\"\n",
    "    if isinstance(x, list):\n",
    "        return \", \".join(map(str, x))\n",
    "    return str(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dccfe9b6-2006-41d8-9841-f4d49e6ad6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanitization complete.\n",
      "Train size: (10796, 4)\n",
      "Val size:   (1349, 4)\n",
      "Test size:  (1350, 4)\n"
     ]
    }
   ],
   "source": [
    "for df_temp in [train_df, val_df, test_df]:\n",
    "    df_temp[\"ingredients_text\"] = df_temp[\"ingredients_text\"].apply(clean_field)\n",
    "    df_temp[\"target_text\"]      = df_temp[\"target_text\"].apply(clean_field)\n",
    "\n",
    "print(\"Sanitization complete.\")\n",
    "print(\"Train size:\", train_df.shape)\n",
    "print(\"Val size:  \", val_df.shape)\n",
    "print(\"Test size: \", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a719d56f-5f62-4b1e-b18d-e4db306c2493",
   "metadata": {},
   "source": [
    "### Convert Pandas → HuggingFace Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b282ba2-71b9-47f1-9156-a275e3ef350d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Title', 'ingredients_text', 'target_text', 'Image_Name'],\n",
       "    num_rows: 10796\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = Dataset.from_pandas(train_df)\n",
    "val_ds   = Dataset.from_pandas(val_df)\n",
    "test_ds  = Dataset.from_pandas(test_df)\n",
    "\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327ca63d-6f45-40e9-be0c-31fbb5f8c1a6",
   "metadata": {},
   "source": [
    "### Load Flan-T5-Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56ba1d33-0b22-43e0-bbb3-29dd96874b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = \"google/flan-t5-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bb74e8-79d3-45b9-9e32-3e87a05f9649",
   "metadata": {},
   "source": [
    "### Configure LoRA (Low-Rank Adaptation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dbeb467-7607-4e46-b8a7-26b50e878130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,769,472 || all params: 249,347,328 || trainable%: 0.7096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForSeq2SeqLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): T5ForConditionalGeneration(\n",
       "      (shared): Embedding(32128, 768)\n",
       "      (encoder): T5Stack(\n",
       "        (embed_tokens): Embedding(32128, 768)\n",
       "        (block): ModuleList(\n",
       "          (0): T5Block(\n",
       "            (layer): ModuleList(\n",
       "              (0): T5LayerSelfAttention(\n",
       "                (SelfAttention): T5Attention(\n",
       "                  (q): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (v): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (relative_attention_bias): Embedding(32, 12)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): T5LayerFF(\n",
       "                (DenseReluDense): T5DenseGatedActDense(\n",
       "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (act): NewGELUActivation()\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1-11): 11 x T5Block(\n",
       "            (layer): ModuleList(\n",
       "              (0): T5LayerSelfAttention(\n",
       "                (SelfAttention): T5Attention(\n",
       "                  (q): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (v): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): T5LayerFF(\n",
       "                (DenseReluDense): T5DenseGatedActDense(\n",
       "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (act): NewGELUActivation()\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (decoder): T5Stack(\n",
       "        (embed_tokens): Embedding(32128, 768)\n",
       "        (block): ModuleList(\n",
       "          (0): T5Block(\n",
       "            (layer): ModuleList(\n",
       "              (0): T5LayerSelfAttention(\n",
       "                (SelfAttention): T5Attention(\n",
       "                  (q): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (v): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (relative_attention_bias): Embedding(32, 12)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): T5LayerCrossAttention(\n",
       "                (EncDecAttention): T5Attention(\n",
       "                  (q): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (v): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (2): T5LayerFF(\n",
       "                (DenseReluDense): T5DenseGatedActDense(\n",
       "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (act): NewGELUActivation()\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1-11): 11 x T5Block(\n",
       "            (layer): ModuleList(\n",
       "              (0): T5LayerSelfAttention(\n",
       "                (SelfAttention): T5Attention(\n",
       "                  (q): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (v): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): T5LayerCrossAttention(\n",
       "                (EncDecAttention): T5Attention(\n",
       "                  (q): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (v): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (2): T5LayerFF(\n",
       "                (DenseReluDense): T5DenseGatedActDense(\n",
       "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (act): NewGELUActivation()\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],  \n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828dfef0-516c-40ad-b84f-7aa291b6370b",
   "metadata": {},
   "source": [
    "### Tokenization & Prompt Design\n",
    "\n",
    "For each example we construct:\n",
    "\n",
    "**Input (to the model):**\n",
    "\n",
    "> \"Given the following ingredients: {ingredients_text}\\nWrite a recipe with a title and step-by-step instructions.\"\n",
    "\n",
    "**Target (to be generated):**\n",
    "\n",
    "`target_text` (from preprocessing):\n",
    "> \"Title: ...\\nInstructions: ...\"\n",
    "\n",
    "We also cap the sequence lengths to fit Apple M2 memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0d52cb0-154c-41b5-82f8-d7f22840db71",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_INPUT_LEN = 256\n",
    "MAX_TARGET_LEN = 256\n",
    "\n",
    "def preprocess_function(batch):\n",
    "    inputs = [\n",
    "        f\"Given the following ingredients: {ing}\\n\"\n",
    "        f\"Write a cooking recipe with a clear title and step-by-step instructions.\"\n",
    "        for ing in batch[\"ingredients_text\"]\n",
    "    ]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=MAX_INPUT_LEN,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            batch[\"target_text\"],\n",
    "            max_length=MAX_TARGET_LEN,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "115e5cd7-feb8-47f1-a972-d99ad83e6939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe243f9c903401bb1460a4a1b059cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10796 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aml/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:4034: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc00501e8f674499b1ff7d680d9ab09b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4ad7af5802412ead7f332bd582b5ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1350 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Title', 'ingredients_text', 'target_text', 'Image_Name', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 10796\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tok = train_ds.map(preprocess_function, batched=True)\n",
    "val_tok   = val_ds.map(preprocess_function, batched=True)\n",
    "test_tok  = test_ds.map(preprocess_function, batched=True)\n",
    "\n",
    "train_tok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38bf946-c994-496c-ac52-6490d55d8929",
   "metadata": {},
   "source": [
    "### Data Collator\n",
    "\n",
    "We use `DataCollatorForSeq2Seq` for dynamic padding during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9c429c2-6a06-4860-b53a-50620ab515e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5f71a2-79c0-4df8-876e-c6fb9ffa02fe",
   "metadata": {},
   "source": [
    "### Evaluation Metrics: ROUGE-L and BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f420dadd-0cdc-400c-8b76-e412e906db1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "bleu = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "\n",
    "\n",
    "    preds = preds.tolist()\n",
    "    labels = labels.tolist()\n",
    "\n",
    "    clean_preds = []\n",
    "    for seq in preds:\n",
    "        clean_seq = []\n",
    "        for tok in seq:\n",
    "            if isinstance(tok, int) and 0 <= tok < tokenizer.vocab_size:\n",
    "                clean_seq.append(tok)\n",
    "            else:\n",
    "                clean_seq.append(tokenizer.pad_token_id)\n",
    "        clean_preds.append(clean_seq)\n",
    "\n",
    "    clean_labels = []\n",
    "    for seq in labels:\n",
    "        clean_seq = []\n",
    "        for tok in seq:\n",
    "            if tok == -100 or tok is None:\n",
    "                clean_seq.append(tokenizer.pad_token_id)\n",
    "            else:\n",
    "                clean_seq.append(tok)\n",
    "        clean_labels.append(clean_seq)\n",
    "\n",
    "    pred_texts = tokenizer.batch_decode(clean_preds, skip_special_tokens=True)\n",
    "    label_texts = tokenizer.batch_decode(clean_labels, skip_special_tokens=True)\n",
    "\n",
    "    rouge_res = rouge.compute(predictions=pred_texts, references=label_texts)\n",
    "    bleu_res = bleu.compute(\n",
    "        predictions=pred_texts,\n",
    "        references=[[ref] for ref in label_texts]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"rougeL\": rouge_res[\"rougeL\"],\n",
    "        \"bleu\": bleu_res[\"score\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b3230a-3c96-47ff-9393-00b660f39f33",
   "metadata": {},
   "source": [
    "### Training Configuration\n",
    "\n",
    "We tune:\n",
    "\n",
    "- Flan-T5-Base with LoRA\n",
    "- Batch size = 1 on M2\n",
    "- 3 epochs (you can increase to 4–5 later)\n",
    "- No checkpoint saving (to avoid disk overflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a9f65df-87a3-43a7-a805-d5de30d54611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqTrainingArguments(output_dir='model/flan_t5_appetite_checkpoints', overwrite_output_dir=False, do_train=False, do_eval=False, do_predict=False, eval_strategy=<IntervalStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=1, per_device_eval_batch_size=1, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, eval_delay=0, torch_empty_cache_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, lr_scheduler_kwargs={}, warmup_ratio=0.0, warmup_steps=0, log_level='passive', log_level_replica='warning', log_on_each_node=True, logging_dir='model/flan_t5_appetite_checkpoints/runs/Nov18_11-22-51_Sharaths-MacBook-Air.local', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=False, logging_steps=500, logging_nan_inf_filter=True, save_strategy=<SaveStrategy.NO: 'no'>, save_steps=500, save_total_limit=None, save_safetensors=True, save_on_each_node=False, save_only_model=False, restore_callback_states_from_checkpoint=False, no_cuda=False, use_cpu=False, use_mps_device=False, seed=42, data_seed=None, jit_mode_eval=False, bf16=False, fp16=False, fp16_opt_level='O1', half_precision_backend='auto', bf16_full_eval=False, fp16_full_eval=False, tf32=None, local_rank=0, ddp_backend=None, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=None, dataloader_num_workers=0, dataloader_prefetch_factor=None, past_index=-1, run_name=None, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, fsdp=[], fsdp_min_num_params=0, fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}, fsdp_transformer_layer_cls_to_wrap=None, accelerator_config=AcceleratorConfig(split_batches=False, dispatch_batches=None, even_batches=True, use_seedable_sampler=True, non_blocking=False, gradient_accumulation_kwargs=None, use_configured_state=False), parallelism_config=None, deepspeed=None, label_smoothing_factor=0.0, optim=<OptimizerNames.ADAMW_TORCH_FUSED: 'adamw_torch_fused'>, optim_args=None, adafactor=False, group_by_length=False, length_column_name='length', report_to=[], project='huggingface', trackio_space_id='trackio', ddp_find_unused_parameters=None, ddp_bucket_cap_mb=None, ddp_broadcast_buffers=None, dataloader_pin_memory=True, dataloader_persistent_workers=False, skip_memory_metrics=True, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, hub_model_id=None, hub_strategy=<HubStrategy.EVERY_SAVE: 'every_save'>, hub_token=None, hub_private_repo=None, hub_always_push=False, hub_revision=None, gradient_checkpointing=False, gradient_checkpointing_kwargs=None, include_inputs_for_metrics=False, include_for_metrics=[], eval_do_concat_batches=True, fp16_backend='auto', push_to_hub_model_id=None, push_to_hub_organization=None, push_to_hub_token=None, mp_parameters='', auto_find_batch_size=False, full_determinism=False, torchdynamo=None, ray_scope='last', ddp_timeout=1800, torch_compile=False, torch_compile_backend=None, torch_compile_mode=None, include_tokens_per_second=False, include_num_input_tokens_seen='no', neftune_noise_alpha=None, optim_target_modules=None, batch_eval_metrics=False, eval_on_start=False, use_liger_kernel=False, liger_kernel_config=None, eval_use_gather_object=False, average_tokens_across_devices=True, sortish_sampler=False, predict_with_generate=True, generation_max_length=256, generation_num_beams=None, generation_config=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 1 if device == \"mps\" else 2\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"model/flan_t5_appetite_checkpoints\",\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=500,\n",
    "    save_strategy=\"no\",       \n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=256,\n",
    ")\n",
    "\n",
    "training_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38936373-378d-4123-b77b-270975d8671c",
   "metadata": {},
   "source": [
    "### Initialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9558ed54-07b7-4f1a-8ca8-7f7deeb495bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ry/nw2d4nm51zj7xgfrvxnrzz440000gn/T/ipykernel_1198/2710965869.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.trainer_seq2seq.Seq2SeqTrainer at 0x30ef5a2d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=val_tok,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5251b7-5345-4c9a-9bda-b976bfbbe2f5",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "148c0a99-d1b6-40c2-9a44-a3ecf1d2a0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aml/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32388' max='32388' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32388/32388 3:16:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>6.166600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.682300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.201500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.018700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.916000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.916500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.955500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.899200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.894000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.925700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.904400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.897400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.829700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.809100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.824500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>1.843700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.835600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>1.808100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.830600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>1.766500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>1.822600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>1.780400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>1.777600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>1.776000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>1.771800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>1.759800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>1.787300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>1.783600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.745600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>1.812300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>1.773000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>1.749900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>1.776500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>1.756700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>1.735900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>1.770600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>1.733200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>1.755500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.784700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>1.726700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>1.766100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>1.737000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>1.753900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>1.756900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>1.738800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>1.757700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>1.732900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>1.744600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.701800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>1.692400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>1.729200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>1.665200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>1.703800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>1.721600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>1.762600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>1.734800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>1.773700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>1.755400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.721800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>1.727800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>1.738700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>1.754500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>1.740100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=32388, training_loss=1.874864421598084, metrics={'train_runtime': 11807.3115, 'train_samples_per_second': 2.743, 'train_steps_per_second': 2.743, 'total_flos': 1.1176988201975808e+16, 'train_loss': 1.874864421598084, 'epoch': 3.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result = trainer.train()\n",
    "train_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb9a785-0bbd-48b9-b889-3705d76eb9df",
   "metadata": {},
   "source": [
    "### Evaluate on Test Set\n",
    "\n",
    "We compute ROUGE-L and BLEU on the held-out test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a645557e-aaef-479a-9538-57451042631d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aml/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.547447919845581,\n",
       " 'eval_model_preparation_time': 0.0108,\n",
       " 'eval_rougeL': 0.22973915357940208,\n",
       " 'eval_bleu': 7.959352841736187,\n",
       " 'eval_runtime': 5476.317,\n",
       " 'eval_samples_per_second': 0.247,\n",
       " 'eval_steps_per_second': 0.247,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics = trainer.evaluate(test_tok)\n",
    "test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eae906e-4dfd-4295-9b95-d738e58234bc",
   "metadata": {},
   "source": [
    "### Save Final Model\n",
    "\n",
    "We save the LoRA-adapted Flan-T5-Base model and tokenizer for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75942aef-37b1-4f91-b117-1885d30a5002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: model/flan_t5_appetite_lora\n"
     ]
    }
   ],
   "source": [
    "SAVE_DIR = \"model/flan_t5_appetite_lora\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "trainer.save_model(SAVE_DIR)\n",
    "tokenizer.save_pretrained(SAVE_DIR)\n",
    "\n",
    "print(\"Model saved to:\", SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580d4b28-5866-4256-a83b-2ceb78d548e3",
   "metadata": {},
   "source": [
    "### Quick Inference Test\n",
    "\n",
    "We test the model on a sample ingredient list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f21de1d-7f89-4f28-abda-46f7c809b409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INGREDIENTS:\n",
      " Olive oil (for pan), 5 1/2 pounds sweet potatoes, peeled, cut into 1 1/2\" pieces, 2 teaspoons kosher salt, divided, plus more, 1 1/4 cups pure maple syrup, divided, 2 cups pecan halves (about 7 ounces), 1 1/2 teaspoons freshly ground black pepper, divided\n",
      "\n",
      "GENERATED RECIPE:\n",
      "\n",
      "Title: Sweet Potatoes with Maple Syrup and Pecans \n",
      "\n",
      "Instructions:\n",
      " Preheat oven to 350°F.\n",
      "Heat oil in a large skillet over medium-high heat.\n",
      "Add sweet potatoes and cook, stirring occasionally, until tender, about 5 minutes.\n",
      "Stir in maple syrup, pecans, and pepper.\n",
      "Cook, stirring frequently, until sweet potatoes are tender, 8 to 10 minutes.\n",
      "Transfer sweet potatoes to a bowl and let cool, covered, about 1 hour.\n",
      "Meanwhile, heat remaining 2 tablespoons oil in another skillet over high heat, stirring often, until golden brown, about 2 minutes.\n",
      "Add pecan halves and pepper to pan and cook until caramelized, about 3 minutes.\n",
      "Remove from heat and stir in remaining 1 tablespoon maple syrup and pecan.\n",
      "Add pepper and continue cooking, stirring constantly, until mixture thickens, about 4 minutes.\n",
      "Serve warm.\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "def generate_recipe(ingredients_text, max_new_tokens=256):\n",
    "\n",
    "    prompt = (\n",
    "        f\"Given the following ingredients: {ingredients_text}\\n\"\n",
    "        f\"Write a well-formatted cooking recipe.\\n\"\n",
    "        f\"Format STRICTLY as:\\n\"\n",
    "        f\"Title: <recipe title>\\n\"\n",
    "        f\"\\n\"\n",
    "        f\"Instructions:\\n\"\n",
    "        f\"1. <step 1>\\n\"\n",
    "        f\"2. <step 2>\\n\"\n",
    "        f\"3. <step 3>\\n\"\n",
    "        f\"Each step MUST be on a new line. with step numbers\\n\"\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True,\n",
    "                       max_length=256).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            num_beams=4,\n",
    "            early_stopping=True,\n",
    "            no_repeat_ngram_size=3\n",
    "        )\n",
    "\n",
    "    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    text = text.replace(\"Instructions:\", \"\\n\\nInstructions:\\n\")\n",
    "    text = text.replace(\". \", \".\\n\")\n",
    "\n",
    "    return text\n",
    "sample = train_df[\"ingredients_text\"].iloc[0]\n",
    "print(\"INGREDIENTS:\\n\", sample)\n",
    "print(\"\\nGENERATED RECIPE:\\n\")\n",
    "print(generate_recipe(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee3dd2c-1b16-4e41-a64a-5d6b6adf5040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aml]",
   "language": "python",
   "name": "conda-env-aml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
